{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630db218",
   "metadata": {},
   "source": [
    "# Exploratory & A/B Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00674b",
   "metadata": {},
   "source": [
    "## 1. Subject Line A/B Performance\n",
    "\n",
    "* Q1: Do variant A vs B subject lines produce statistically significant differences in open rate?\n",
    "\n",
    "* Q2:  Is the effect of subject variant on open rate consistent across segments and channels, or explained by confounders\n",
    "\n",
    "## 2. Timing & Frequency Effects\n",
    "\n",
    "* Q3: Does send time (hour/day) affect open/CTR?\n",
    "\n",
    "* Q4: How does customer engagement fatigue—measured by cumulative opens and inactivity periods—influence unsubscribe rates and purchase likelihood?\n",
    "\n",
    "## 3. Segment-Level Insights\n",
    "\n",
    "* Q5: Which customer segments (RFM quintiles, new vs. repeat) respond best to promotions vs. newsletters?\n",
    "\n",
    "* Q6: What is the interplay between purchase frequency and email engagement?\n",
    "\n",
    "* Campaign→Order Link\n",
    "\n",
    "*  Q7: For engaged customers (opened/clicked), what is the uplift in next-30-day order rate and average order value vs. non-openers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae3fd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "email_campaign_df = pd.read_csv('../data/email_campaigns.csv')\n",
    "for col in ['campaign_id', 'channel', 'segment', 'customer_id', 'recipient_name', 'send_timestamp', 'subject_variant', 'subject_line', 'device']:\n",
    "    email_campaign_df[col] = email_campaign_df[col].astype('string')\n",
    "\n",
    "email_engagement_df = pd.read_csv('../data/email_engagement.csv')\n",
    "for col in ['campaign_id', 'customer_id', 'send_timestamp', 'subject_variant']:\n",
    "    email_engagement_df[col] = email_engagement_df[col].astype('string')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert timestamps\n",
    "email_campaign_df['send_timestamp'] = pd.to_datetime(email_campaign_df['send_timestamp'], errors='coerce')\n",
    "email_engagement_df['send_timestamp'] = pd.to_datetime(email_engagement_df['send_timestamp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4aa655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'customer_id', 'send_timestamp', 'subject_variant',\n",
       "       'opened', 'clicked', 'unsubscribed', 'purchase', 'revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_engagement_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479a9bd",
   "metadata": {},
   "source": [
    "## 1. Subject Line A/B Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39d4d7",
   "metadata": {},
   "source": [
    "### Q1: Do variant A vs B subject lines produce statistically significant differences in open rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84188fcf",
   "metadata": {},
   "source": [
    "#### Statistical test (e.g., two-proportion z-test) for significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6331743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Stat: -32.86374315017827, p-value: 7.248358126247467e-237\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "\n",
    "# Aggregate open counts by variant \n",
    "\n",
    "agg= (email_engagement_df\n",
    "      .groupby('subject_variant')['opened']\n",
    "      .agg(['sum','count'])\n",
    "      )\n",
    "\n",
    "\n",
    "## Variant A vs Variant B\n",
    "\n",
    "open = agg.loc[['A','B'],'sum'] \n",
    "\n",
    "totals = agg.loc[['A','B'],'count']\n",
    "\n",
    "\n",
    "# two-propertion z test\n",
    "stats, pval = proportions_ztest(open,totals)\n",
    "\n",
    "print(f\"Z-Stat: {stats}, p-value: {pval}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278789c",
   "metadata": {},
   "source": [
    "#### Effect size calculation (difference in open rate) for praticial impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89dcfb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size (A-B): -0.009370\n",
      "95% CI: (-0.00993, -0.00881)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import confint_proportions_2indep\n",
    "\n",
    "#open rates \n",
    "rate_A = open.iloc[0]/totals.iloc[0]\n",
    "rate_B = open.iloc[1]/totals.iloc[1]\n",
    "\n",
    "effect_size= rate_A-rate_B\n",
    "\n",
    "\n",
    "## confidence interval for difference \n",
    "# method = wald or score can be used \n",
    "\n",
    "lower,upper = confint_proportions_2indep(open.iloc[0],totals.iloc[0],open.iloc[1],totals.iloc[1],method='score')\n",
    "\n",
    "print(f\"Effect size (A-B): {effect_size:5f}\")\n",
    "\n",
    "print(f\"95% CI: ({lower:.5f}, {upper:.5f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286c866",
   "metadata": {},
   "source": [
    "### *Summary for Subject Line A/B Performance*\n",
    "\n",
    "The statistical analysis shows a highly significant difference in open rates between subject line variants A and B.\n",
    "\n",
    "- Two-proportion z-test result: Z = -32.86, p-value ≈ 0, indicating the difference is not due to chance.\n",
    "- Effect size (A - B): -0.00937, meaning variant A's open rate is approximately 0.9% lower than variant B's.\n",
    "-  95% confidence interval for the difference: (-0.00993, -0.00881), confirming precision and that the difference is consistently below zero.\n",
    "\n",
    "Conclusion: Subject line variant has a statistically significant and measurable impact on open rate. The difference is precise and robust given the large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c9b34",
   "metadata": {},
   "source": [
    "#### Q2: Is the effect of subject variant on open rate consistent across segments and channels, or explained by confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671a826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge email_campaign_df with email_engagement_df to add channel and segment info to engagement data\n",
    "# Drop duplicates to keep unique campaign_id with channel and segment\n",
    "campaign_agg = email_campaign_df[['campaign_id', 'channel', 'segment']].drop_duplicates(subset=['campaign_id']).copy()\n",
    "\n",
    "# Merge aggregated campaign info with engagement data\n",
    "merged_df = email_engagement_df.merge(campaign_agg, on='campaign_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89485806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'customer_id', 'send_timestamp', 'subject_variant',\n",
       "       'opened', 'clicked', 'unsubscribed', 'purchase', 'revenue', 'channel',\n",
       "       'segment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f94ddc",
   "metadata": {},
   "source": [
    " #### logistic regression to model open probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cff956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.353206\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 opened   No. Observations:              4946692\n",
      "Model:                          Logit   Df Residuals:                  4946672\n",
      "Method:                           MLE   Df Model:                           19\n",
      "Date:                Wed, 06 Aug 2025   Pseudo R-squ.:               0.0009951\n",
      "Time:                        13:04:23   Log-Likelihood:            -1.7472e+06\n",
      "converged:                       True   LL-Null:                   -1.7489e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================================================\n",
      "                                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                         -2.2194      0.016   -138.942      0.000      -2.251      -2.188\n",
      "subject_variant[T.B]                               0.0950      0.022      4.281      0.000       0.052       0.139\n",
      "channel[T.loyalty]                                 0.1717      0.019      9.011      0.000       0.134       0.209\n",
      "channel[T.newsletter]                              0.0087      0.016      0.542      0.588      -0.023       0.040\n",
      "channel[T.promo]                                   0.1748      0.016     11.126      0.000       0.144       0.206\n",
      "channel[T.survey]                                  0.0692      0.025      2.765      0.006       0.020       0.118\n",
      "channel[T.transactional]                           0.0741      0.017      4.392      0.000       0.041       0.107\n",
      "segment[T.inactive]                                0.0144      0.007      2.045      0.041       0.001       0.028\n",
      "segment[T.new_subscriber]                          0.0058      0.008      0.715      0.475      -0.010       0.022\n",
      "segment[T.occasional]                              0.0134      0.006      2.156      0.031       0.001       0.026\n",
      "segment[T.repeat_buyer]                           -0.0141      0.006     -2.388      0.017      -0.026      -0.003\n",
      "subject_variant[T.B]:channel[T.loyalty]            0.0108      0.026      0.409      0.683      -0.041       0.063\n",
      "subject_variant[T.B]:channel[T.newsletter]         0.0281      0.022      1.265      0.206      -0.015       0.072\n",
      "subject_variant[T.B]:channel[T.promo]             -0.0094      0.022     -0.431      0.666      -0.052       0.033\n",
      "subject_variant[T.B]:channel[T.survey]             0.0125      0.035      0.359      0.720      -0.056       0.080\n",
      "subject_variant[T.B]:channel[T.transactional]     -0.0013      0.023     -0.054      0.957      -0.047       0.045\n",
      "subject_variant[T.B]:segment[T.inactive]          -0.0110      0.010     -1.123      0.262      -0.030       0.008\n",
      "subject_variant[T.B]:segment[T.new_subscriber]    -0.0128      0.011     -1.143      0.253      -0.035       0.009\n",
      "subject_variant[T.B]:segment[T.occasional]         0.0026      0.009      0.302      0.763      -0.014       0.019\n",
      "subject_variant[T.B]:segment[T.repeat_buyer]      -0.0071      0.008     -0.862      0.389      -0.023       0.009\n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "## prepare merged df with nesessary columns \n",
    "## ensuring categorical variables are treated as such \n",
    "\n",
    "merged_df['subject_variant']= merged_df['subject_variant'].astype('category')\n",
    "merged_df['channel']= merged_df['channel'].astype('category')\n",
    "merged_df['segment']= merged_df['segment'].astype('category')\n",
    "\n",
    "\n",
    "# Logistic regression formula with interactions\n",
    "formula = 'opened ~ subject_variant + channel + segment + subject_variant:channel + subject_variant:segment'\n",
    "\n",
    "\n",
    "# fit model using statsmodel \n",
    "model = smf.logit(formula=formula, data=merged_df).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40553b",
   "metadata": {},
   "source": [
    "#### *Model Significance Order and Conclusion*\n",
    "\n",
    "Order of predictors by statistical significance (lowest to highest p-value):\n",
    "\n",
    "1. channel[T.promo] (p ≈ 0.000, z=11.126) - strongest positive effect  \n",
    "2. channel[T.loyalty] (p ≈ 0.000, z=9.011)  \n",
    "3. channel[T.transactional] (p ≈ 0.000, z=4.392)  \n",
    "4. subject_variant[T.B] (p ≈ 0.000, z=4.281)  \n",
    "5. channel[T.survey] (p=0.006, z=2.765)  \n",
    "6. segment[T.occasional] (p=0.031, z=2.156)  \n",
    "7. segment[T.inactive] (p=0.041, z=2.045)  \n",
    "8. channel[T.newsletter] (p=0.588, not significant)  \n",
    "\n",
    "**Conclusion:**  \n",
    "\n",
    "The promotional, loyalty, and transactional channels significantly increase the odds of email opens, with promo having the largest effect.  \n",
    "\n",
    "Subject variant B also significantly increases open likelihood but with a smaller effect than these top channels.  \n",
    "\n",
    "Segments occasional and inactive show small but statistically significant effects, while the newsletter channel has no significant impact on open rates.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c66762",
   "metadata": {},
   "source": [
    "## 2. Timing & Frequency Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb0833",
   "metadata": {},
   "source": [
    "### Q3: Does send time (hour/day) affect open/CTR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388358c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (merged_df\n",
    "           .groupby([merged_df['send_timestamp'].dt.dayofweek.rename('day_sent'),\n",
    "                     merged_df['send_timestamp'].dt.hour.rename('hour_sent')])\n",
    "           .agg(opened_sum=('opened', 'sum'),\n",
    "                clicked_sum=('clicked', 'sum'),\n",
    "                email_sent=('campaign_id', 'count'))\n",
    "          ).reset_index()\n",
    "\n",
    "grouped['open_rate'] = grouped['opened_sum'] / grouped['email_sent']\n",
    "grouped['ctr'] = grouped['clicked_sum'] / grouped['email_sent']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ca19d",
   "metadata": {},
   "source": [
    "#### Logistic regression to test impact of send day and hour on email open probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684f66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['day_sent']= merged_df['send_timestamp'].dt.dayofweek\n",
    "merged_df['hour_sent']= merged_df['send_timestamp'].dt.hour\n",
    "\n",
    "\n",
    "logit_df = merged_df[['opened', 'day_sent', 'hour_sent']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27dc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Generalized Linear Model Regression Results                      \n",
      "=======================================================================================\n",
      "Dep. Variable:     ['clicked_sum', 'failures']   No. Observations:                   44\n",
      "Model:                                     GLM   Df Residuals:                 10747422\n",
      "Model Family:                         Binomial   Df Model:                           17\n",
      "Link Function:                           Logit   Scale:                          1.0000\n",
      "Method:                                   IRLS   Log-Likelihood:            -5.0037e+07\n",
      "Date:                         Wed, 06 Aug 2025   Deviance:                   5.2440e+06\n",
      "Time:                                 13:30:56   Pearson chi2:                 5.25e+06\n",
      "No. Iterations:                            100   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:                     nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          -5.2574   9.88e-05  -5.32e+04      0.000      -5.258      -5.257\n",
      "day_sent[T.1]      -0.0676   2.81e-05  -2408.268      0.000      -0.068      -0.068\n",
      "day_sent[T.2]      -0.0158   2.75e-05   -576.309      0.000      -0.016      -0.016\n",
      "day_sent[T.3]      -0.0585    2.8e-05  -2088.181      0.000      -0.059      -0.058\n",
      "day_sent[T.4]      -0.0823   2.77e-05  -2974.357      0.000      -0.082      -0.082\n",
      "day_sent[T.5]      -0.2284   5.79e-05  -3942.795      0.000      -0.229      -0.228\n",
      "day_sent[T.6]      -0.1926   5.61e-05  -3434.858      0.000      -0.193      -0.192\n",
      "hour_sent[T.10]     0.0073    9.8e-05     74.114      0.000       0.007       0.007\n",
      "hour_sent[T.11]    -0.0053    9.8e-05    -54.490      0.000      -0.006      -0.005\n",
      "hour_sent[T.12]    -0.1887      0.000  -1492.894      0.000      -0.189      -0.188\n",
      "hour_sent[T.13]    -0.1878      0.000  -1486.109      0.000      -0.188      -0.188\n",
      "hour_sent[T.14]    -0.1607      0.000  -1278.215      0.000      -0.161      -0.160\n",
      "hour_sent[T.15]    -0.1825      0.000  -1443.194      0.000      -0.183      -0.182\n",
      "hour_sent[T.16]    -0.1780      0.000  -1409.497      0.000      -0.178      -0.178\n",
      "hour_sent[T.17]    -0.2335      0.000  -1822.941      0.000      -0.234      -0.233\n",
      "hour_sent[T.18]    -0.3962   9.87e-05  -4015.220      0.000      -0.396      -0.396\n",
      "hour_sent[T.19]    -0.4207   9.87e-05  -4261.292      0.000      -0.421      -0.420\n",
      "hour_sent[T.20]    -0.4107      0.000  -3047.483      0.000      -0.411      -0.410\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Random 1% sample (≈ 100k rows) to fit model\n",
    "sample_df = merged_df.sample(frac=0.01, random_state=42)\n",
    "\n",
    "# Convert to categorical\n",
    "sample_df['day_sent'] = sample_df['day_sent'].astype('category')\n",
    "sample_df['hour_sent'] = sample_df['hour_sent'].astype('category')\n",
    "\n",
    "# Fit logistic regression\n",
    "formula = 'opened ~ day_sent + hour_sent'\n",
    "model = smf.logit(formula=formula, data=sample_df)\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9570c",
   "metadata": {},
   "source": [
    "#### Logistic regression to test impact of send day and hour on email CTR probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa6ca569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Generalized Linear Model Regression Results                      \n",
      "=======================================================================================\n",
      "Dep. Variable:     ['clicked_sum', 'failures']   No. Observations:                   44\n",
      "Model:                                     GLM   Df Residuals:                       26\n",
      "Model Family:                         Binomial   Df Model:                           17\n",
      "Link Function:                           Logit   Scale:                          1.0000\n",
      "Method:                                   IRLS   Log-Likelihood:                -197.07\n",
      "Date:                         Wed, 06 Aug 2025   Deviance:                       20.307\n",
      "Time:                                 13:38:04   Pearson chi2:                     20.3\n",
      "No. Iterations:                              9   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:                     nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          -5.2566      0.037   -143.039      0.000      -5.329      -5.185\n",
      "day_sent[T.1]      -0.0676      0.018     -3.857      0.000      -0.102      -0.033\n",
      "day_sent[T.2]      -0.0159      0.017     -0.920      0.358      -0.050       0.018\n",
      "day_sent[T.3]      -0.0585      0.017     -3.344      0.001      -0.093      -0.024\n",
      "day_sent[T.4]      -0.0823      0.017     -4.716      0.000      -0.116      -0.048\n",
      "day_sent[T.5]      -0.2292      0.023    -10.029      0.000      -0.274      -0.184\n",
      "day_sent[T.6]      -0.1934      0.022     -8.603      0.000      -0.237      -0.149\n",
      "hour_sent[T.10]     0.0066      0.036      0.185      0.853      -0.063       0.077\n",
      "hour_sent[T.11]    -0.0047      0.036     -0.133      0.894      -0.075       0.065\n",
      "hour_sent[T.12]    -0.1882      0.045     -4.154      0.000      -0.277      -0.099\n",
      "hour_sent[T.13]    -0.1880      0.045     -4.151      0.000      -0.277      -0.099\n",
      "hour_sent[T.14]    -0.1609      0.045     -3.574      0.000      -0.249      -0.073\n",
      "hour_sent[T.15]    -0.1814      0.045     -4.007      0.000      -0.270      -0.093\n",
      "hour_sent[T.16]    -0.1766      0.045     -3.907      0.000      -0.265      -0.088\n",
      "hour_sent[T.17]    -0.2333      0.046     -5.085      0.000      -0.323      -0.143\n",
      "hour_sent[T.18]    -0.3963      0.036    -10.899      0.000      -0.468      -0.325\n",
      "hour_sent[T.19]    -0.4242      0.036    -11.649      0.000      -0.496      -0.353\n",
      "hour_sent[T.20]    -0.4107      0.048     -8.507      0.000      -0.505      -0.316\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grouped['failures'] = grouped['email_sent'] - grouped['clicked_sum']\n",
    "\n",
    "grouped['day_sent'] = grouped['day_sent'].astype('category')\n",
    "grouped['hour_sent'] = grouped['hour_sent'].astype('category')\n",
    "\n",
    "formula = 'clicked_sum + failures ~ day_sent + hour_sent'\n",
    "\n",
    "model = smf.glm(formula=formula, data=grouped, family=sm.families.Binomial())\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f16da",
   "metadata": {},
   "source": [
    "#### *Summary for open and CTR probability*\n",
    "\n",
    "Conclusion: The model's low pseudo R-squared (0.0025) and coefficients show weak predictive power and inconsistent day/hour effects, suggesting the data is noisy, synthetic, or poorly recorded. The lack of strong positive coefficients means no clear best send time emerges. The dataset or feature engineering likely needs improvement before actionable insights. The data shows Sunday at 00:00 being the most optimal day to send the emails which makes no sense in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1735db28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'customer_id', 'send_timestamp', 'subject_variant',\n",
       "       'opened', 'clicked', 'unsubscribed', 'purchase', 'revenue', 'channel',\n",
       "       'segment', 'day_sent', 'hour_sent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f932d",
   "metadata": {},
   "source": [
    "## Q4: How does customer engagement fatigue-measured by cumulative opens and inactivity periods-influence unsubscribe rates and purchase likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "830d9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85182650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['customer_id'] = df['customer_id'].astype('category')\n",
    "\n",
    "df['purchase'] = df['purchase'].astype('int8')\n",
    "df['send_timestamp'] = pd.to_datetime(df['send_timestamp'])\n",
    "\n",
    "## sort the values by customer_id and send timestamp\n",
    "df.sort_values(['customer_id', 'send_timestamp'], inplace=True)\n",
    "\n",
    "## identify first row per customer \n",
    "df['is_first']= df.groupby('customer_id',observed=True).cumcount()==0\n",
    "\n",
    "## has any prior purchase? \n",
    "df['prior_purchase']= ( \n",
    "    df.groupby('customer_id',observed=True)['purchase']\n",
    "    .transform(lambda x: x.shift().cummax().fillna(0)))\n",
    "\n",
    "## assing segments \n",
    "df['segment']='inactive'\n",
    "df.loc[df['is_first'],'segment']= 'new'\n",
    "\n",
    "# if customer is not new and has prior purchase then they are a repat  \n",
    "df.loc[(~df['is_first']) & (df['prior_purchase']>0),'segment']='repeat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e8ab4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_since_last_purchase'] = df.groupby('customer_id',observed=True)['send_timestamp'].diff().dt.days.fillna(0)\n",
    "\n",
    "df['days_since_last_purchase_cum'] = df.groupby('customer_id',observed=True)['days_since_last_purchase'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be946c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680744\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           unsubscribed   No. Observations:                77990\n",
      "Model:                          Logit   Df Residuals:                    77985\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Wed, 06 Aug 2025   Pseudo R-squ.:                 0.01789\n",
      "Time:                        14:06:28   Log-Likelihood:                -53091.\n",
      "converged:                       True   LL-Null:                       -54059.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Intercept                              -0.0476      0.008     -5.961      0.000      -0.063      -0.032\n",
      "segment[T.new]                         -0.0028      0.213     -0.013      0.989      -0.419       0.414\n",
      "segment[T.repeat]                      -0.0406      0.025     -1.627      0.104      -0.090       0.008\n",
      "days_since_last_purchase_cum_scaled    -0.4086      0.012    -33.963      0.000      -0.432      -0.385\n",
      "cumulative_opens_scaled                 0.1312      0.012     10.616      0.000       0.107       0.155\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Create per-customer cumulative opens\n",
    "df['cumulative_opens'] = (\n",
    "    df.groupby('customer_id', observed=True)['opened']\n",
    "      .cumsum()\n",
    ")\n",
    "\n",
    "# Scale continuous predictors to avoid overflow\n",
    "df['cumulative_opens_scaled'] = (\n",
    "    (df['cumulative_opens'] - df['cumulative_opens'].mean()) /\n",
    "    df['cumulative_opens'].std()\n",
    ")\n",
    "df['days_since_last_purchase_cum_scaled'] = (\n",
    "    (df['days_since_last_purchase_cum'] - df['days_since_last_purchase_cum'].mean()) /\n",
    "    df['days_since_last_purchase_cum'].std()\n",
    ")\n",
    "\n",
    "# Stratified sample for unsubscribe model\n",
    "sample_df_unsub = (\n",
    "    df.groupby('unsubscribed', group_keys=False, observed=True)\n",
    "      .sample(n=min(50000, df['unsubscribed'].value_counts().min()),\n",
    "              random_state=42)\n",
    ")\n",
    "\n",
    "# Stratified sample for purchase model\n",
    "sample_df_purchase = (\n",
    "    df.groupby('purchase', group_keys=False, observed=True)\n",
    "      .sample(n=min(50000, df['purchase'].value_counts().min()),\n",
    "              random_state=42)\n",
    ")\n",
    "\n",
    "# Ensure binary outcomes are int\n",
    "sample_df_unsub['unsubscribed'] = sample_df_unsub['unsubscribed'].astype(int)\n",
    "sample_df_purchase['purchase'] = sample_df_purchase['purchase'].astype(int)\n",
    "\n",
    "# Logistic regression: unsubscribe ~ fatigue/inactivity\n",
    "model_unsub = smf.logit(\n",
    "    formula='unsubscribed ~ days_since_last_purchase_cum_scaled + cumulative_opens_scaled + segment',\n",
    "    data=sample_df_unsub\n",
    ").fit()\n",
    "print(model_unsub.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315af5c",
   "metadata": {},
   "source": [
    "#### *Logistic regression: unsubscribe summary*\n",
    "* days_since_last_purchase_cum_scaled is strongly negative (p<0.001). \n",
    "* Customers with longer inactivity periods are significantly less likely to unsubscribe.\n",
    "* cumulative_opens_scaled is strongly positive (p<0.001). Customers with more cumulative opens are significantly more likely to unsubscribe.\n",
    "* Segment type (new vs repeat) is not significant.\n",
    "\n",
    "Conclusion: Engagement fatigue is visible. Frequent openers are at higher unsubscribe risk, while long inactive periods lower that risk. Purchase recency plays a smaller role than cumulative engagement.\n",
    "\n",
    "*Conclusion* unsubscribe risk is driven more by over-engagement than by inactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3ccdacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600360\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               purchase   No. Observations:                10092\n",
      "Model:                          Logit   Df Residuals:                    10088\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Wed, 06 Aug 2025   Pseudo R-squ.:                  0.1339\n",
      "Time:                        14:14:40   Log-Likelihood:                -6058.8\n",
      "converged:                       True   LL-Null:                       -6995.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================================\n",
      "                                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Intercept                              -0.0645      0.025     -2.534      0.011      -0.114      -0.015\n",
      "C(segment)[T.repeat]                    0.4901      0.059      8.362      0.000       0.375       0.605\n",
      "days_since_last_purchase_cum_scaled     0.0192      0.035      0.555      0.579      -0.049       0.087\n",
      "cumulative_opens_scaled                 0.8800      0.041     21.430      0.000       0.799       0.960\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression: purchase ~ fatigue/inactivity\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Collapse 'new' into 'inactive'\n",
    "sample_df_purchase['segment'] = sample_df_purchase['segment'].replace({'new': 'inactive'})\n",
    "\n",
    "# Scale predictors\n",
    "for col in ['days_since_last_purchase_cum', 'cumulative_opens']:\n",
    "    sample_df_purchase[col + '_scaled'] = (\n",
    "        sample_df_purchase[col] - sample_df_purchase[col].mean()\n",
    "    ) / sample_df_purchase[col].std()\n",
    "\n",
    "# Fit logistic regression\n",
    "model_purchase = smf.logit(\n",
    "    formula='purchase ~ days_since_last_purchase_cum_scaled + cumulative_opens_scaled + C(segment)',\n",
    "    data=sample_df_purchase\n",
    ").fit()\n",
    "print(model_purchase.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57242eee",
   "metadata": {},
   "source": [
    "#### *Summary: Factors Influencing Purchase Likelihood* \n",
    "\n",
    "Logistic regression analysis reveals that customer engagement, measured by cumulative email opens, and customer segment strongly correlate with purchase probability. Specifically, customers in the \"repeat\" segment are significantly more likely to purchase than other segments (coef = 0.49, p < 0.001). Increased cumulative opens also positively predict purchase likelihood (coef = 0.88, p < 0.001), indicating that higher engagement drives conversions.\n",
    "\n",
    "Days since last purchase shows no significant effect (p = 0.579), suggesting that recency of last purchase alone does not predict immediate purchase behavior within this dataset.\n",
    "\n",
    "Overall, these results highlight that repeated engagement and customer loyalty are key drivers of purchase behavior in the email campaign data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
